{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "665f4c7a-59b8-404c-a767-83d88d3171df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664d61ea-49b6-4830-9885-cdb89519b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf89f3a-517a-4849-9cda-777d928ecdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "922b650d-7402-4be9-873b-f7ecdca3f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be49ce0-f825-4e10-9f7a-9a7196368b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23d272b5-441d-4247-bd7a-312345156f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generator(data_dir, generator, subset):\n",
    "    return generator.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        classes=class_names,\n",
    "        shuffle=True if subset == 'training' else False,\n",
    "        subset=subset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf96e448-4121-4709-be40-e6fe671e7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed79e91-0e22-4bea-99f3-9e11f8b56036",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c2b2379-bdf9-4f3b-9af1-17784713aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2297 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = create_data_generator(data_dir, train_datagen, 'training')\n",
    "validation_generator = create_data_generator(data_dir, val_datagen, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35ab5510-2a66-4698-9b00-752d8feffe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kusha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "454aadad-ba02-4b9e-9f76-312458f03c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b0a664-2381-4798-8c7e-6ee71e0bb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a81a75be-26f4-4390-b5ac-034ba5474881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac7e1dc5-1279-419a-ab94-79d7e5c71e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7808e3b-3358-46c8-af1a-d49cff718011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 3s/step - accuracy: 0.5323 - loss: 1.0562 - val_accuracy: 0.7059 - val_loss: 0.7871\n",
      "Epoch 2/20\n",
      "\u001b[1m 1/71\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 3s/step - accuracy: 0.8125 - loss: 0.5255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8125 - loss: 0.5255 - val_accuracy: 0.6897 - val_loss: 0.7375\n",
      "Epoch 3/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 3s/step - accuracy: 0.7606 - loss: 0.6257 - val_accuracy: 0.7500 - val_loss: 0.6614\n",
      "Epoch 4/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7188 - loss: 0.6219 - val_accuracy: 0.5517 - val_loss: 0.9820\n",
      "Epoch 5/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 6s/step - accuracy: 0.7806 - loss: 0.5621 - val_accuracy: 0.7647 - val_loss: 0.6714\n",
      "Epoch 6/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.8750 - loss: 0.5212 - val_accuracy: 0.5862 - val_loss: 1.0049\n",
      "Epoch 7/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 3s/step - accuracy: 0.7803 - loss: 0.5676 - val_accuracy: 0.7868 - val_loss: 0.6530\n",
      "Epoch 8/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.8125 - loss: 0.5263 - val_accuracy: 0.6552 - val_loss: 0.8438\n",
      "Epoch 9/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 3s/step - accuracy: 0.7994 - loss: 0.5296 - val_accuracy: 0.7941 - val_loss: 0.5472\n",
      "Epoch 10/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.4536 - val_accuracy: 0.6552 - val_loss: 0.7327\n",
      "Epoch 11/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1588s\u001b[0m 23s/step - accuracy: 0.8139 - loss: 0.5061 - val_accuracy: 0.7518 - val_loss: 0.6631\n",
      "Epoch 12/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8438 - loss: 0.4148 - val_accuracy: 0.7586 - val_loss: 0.5737\n",
      "Epoch 13/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 3s/step - accuracy: 0.8256 - loss: 0.4909 - val_accuracy: 0.7831 - val_loss: 0.5857\n",
      "Epoch 14/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.8125 - loss: 0.4414 - val_accuracy: 0.7241 - val_loss: 0.6747\n",
      "Epoch 15/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 3s/step - accuracy: 0.8313 - loss: 0.4518 - val_accuracy: 0.7868 - val_loss: 0.6224\n",
      "Epoch 16/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8125 - loss: 0.4522 - val_accuracy: 0.5862 - val_loss: 1.0906\n",
      "Epoch 17/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.8194 - loss: 0.4601 - val_accuracy: 0.7684 - val_loss: 0.6465\n",
      "Epoch 18/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.7812 - loss: 0.6376 - val_accuracy: 0.7586 - val_loss: 0.7270\n",
      "Epoch 19/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 4s/step - accuracy: 0.8115 - loss: 0.4529 - val_accuracy: 0.7794 - val_loss: 0.7115\n",
      "Epoch 20/20\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7812 - loss: 0.5677 - val_accuracy: 0.7931 - val_loss: 0.3362\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e30b74ed-b1fd-459e-b290-2f9694ea6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.7183 - loss: 0.8385\n",
      "Test accuracy: 0.7714\n",
      "Test loss: 0.7077\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7691d8c2-c632-49ee-8039-aed9a411595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('brain_mri_inceptionv2_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8c2f5-e1c0-4dff-a096-25db75788fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
